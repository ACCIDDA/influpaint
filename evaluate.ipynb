{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About WIS\n",
    "Good ressources:\n",
    "-  Supplement of Cramer et al.\n",
    "- code cramer et al. here https://github.com/reichlab/covid19-forecast-evals\n",
    "- obviously https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008618#sec015\n",
    "- [git clone https://github.com/adrian-lison/interval-scoring.git](https://github.com/adrian-lison/interval-scoring/tree/master) Adrian Lison's code for WIS\n",
    "- https://epiforecasts.io/scoringutils/ Scoring utils package -- perhaps best to use ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interval_scoring import scoring\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A modification of Lison's code that splits the calibration in underprediction and overprediction\n",
    "def weighted_interval_score_fast(\n",
    "    observations, alphas, q_dict, weights=None, percent=False, check_consistency=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute weighted interval scores for an array of observations and a number of different predicted intervals.\n",
    "    \n",
    "    This function implements the WIS-score (2). A dictionary with the respective (alpha/2)\n",
    "    and (1-(alpha/2)) quantiles for all alpha levels given in `alphas` needs to be specified.\n",
    "    \n",
    "    This is a more efficient implementation using array operations instead of repeated calls of `interval_score`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    observations : array_like\n",
    "        Ground truth observations.\n",
    "    alphas : iterable\n",
    "        Alpha levels for (1-alpha) intervals.\n",
    "    q_dict : dict\n",
    "        Dictionary with predicted quantiles for all instances in `observations`.\n",
    "    weights : iterable, optional\n",
    "        Corresponding weights for each interval. If `None`, `weights` is set to `alphas`, yielding the WIS^alpha-score.\n",
    "    percent: bool, optional\n",
    "        If `True`, score is scaled by absolute value of observations to yield a percentage error. Default is `False`.\n",
    "    check_consistency: bool, optional\n",
    "        If `True`, quantiles in `q_dict` are checked for consistency. Default is `True`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    total : array_like\n",
    "        Total weighted interval scores.\n",
    "    sharpness : array_like\n",
    "        Sharpness component of weighted interval scores.\n",
    "    calibration : array_like\n",
    "        Calibration component of weighted interval scores.\n",
    "        \n",
    "    (2) Bracher, J., Ray, E. L., Gneiting, T., & Reich, N. G. (2020). Evaluating epidemic forecasts in an interval format. arXiv preprint arXiv:2005.12881.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = np.array(alphas)/2\n",
    "\n",
    "    if not all(alphas[i] <= alphas[i + 1] for i in range(len(alphas) - 1)):\n",
    "        raise ValueError(\"Alpha values must be sorted in ascending order.\")\n",
    "\n",
    "    reversed_weights = list(reversed(weights))\n",
    "\n",
    "    lower_quantiles = [q_dict.get(alpha / 2) for alpha in alphas]\n",
    "    upper_quantiles = [q_dict.get(1 - (alpha / 2)) for alpha in reversed(alphas)]\n",
    "    if any(q is None for q in lower_quantiles) or any(\n",
    "        q is None for q in upper_quantiles\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            f\"Quantile dictionary does not include all necessary quantiles.\"\n",
    "        )\n",
    "\n",
    "    lower_quantiles = np.vstack(lower_quantiles)\n",
    "    upper_quantiles = np.vstack(upper_quantiles)\n",
    "\n",
    "    # Check for consistency\n",
    "    if check_consistency and np.any(\n",
    "        np.diff(np.vstack((lower_quantiles, upper_quantiles)), axis=0) < 0\n",
    "    ):\n",
    "        raise ValueError(\"Quantiles are not consistent.\")\n",
    "\n",
    "    lower_q_alphas = (2 / np.array(alphas)).reshape((-1, 1))\n",
    "    upper_q_alphas = (2 / np.array(list(reversed(alphas)))).reshape((-1, 1))\n",
    "\n",
    "    # compute score components for all intervals\n",
    "    sharpnesses = np.flip(upper_quantiles, axis=0) - lower_quantiles\n",
    "\n",
    "    lower_calibrations = (\n",
    "        np.clip(lower_quantiles - observations, a_min=0, a_max=None) * lower_q_alphas\n",
    "    )\n",
    "    upper_calibrations = (\n",
    "        np.clip(observations - upper_quantiles, a_min=0, a_max=None) * upper_q_alphas\n",
    "    )\n",
    "    calibrations = lower_calibrations + np.flip(upper_calibrations, axis=0)\n",
    "    upper_calibrations = np.flip(upper_calibrations, axis=0)\n",
    "    lower_calibrations = lower_calibrations\n",
    "\n",
    "    # scale to percentage absolute error\n",
    "    if percent:\n",
    "        sharpnesses = sharpnesses / np.abs(observations)\n",
    "        calibrations = calibrations / np.abs(observations)\n",
    "        raise ValueError(\"Not Supported with the calibration split\")\n",
    "\n",
    "    totals = sharpnesses + calibrations\n",
    "\n",
    "    # weigh scores\n",
    "    weights = np.array(weights).reshape((-1, 1))\n",
    "\n",
    "    sharpnesses_weighted = sharpnesses * weights\n",
    "    calibrations_weighted = calibrations * weights\n",
    "    upper_calibrations_weighted = upper_calibrations * weights\n",
    "    lower_calibrations_weighted = lower_calibrations * weights\n",
    "    totals_weighted = totals * weights\n",
    "\n",
    "    # normalize and aggregate all interval scores\n",
    "    weights_sum = np.sum(weights)\n",
    "\n",
    "    sharpnesses_final = np.sum(sharpnesses_weighted, axis=0) / weights_sum\n",
    "    calibrations_final = np.sum(calibrations_weighted, axis=0) / weights_sum\n",
    "    upper_calibrations_final = np.sum(upper_calibrations_weighted, axis=0) / weights_sum\n",
    "    lower_calibrations_final = np.sum(lower_calibrations_weighted, axis=0) / weights_sum\n",
    "    totals_final = np.sum(totals_weighted, axis=0) / weights_sum\n",
    "\n",
    "    return totals_final, sharpnesses_final, calibrations_final, lower_calibrations_final, upper_calibrations_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_Nwk_forecasts(gt, forecasts, n=4) -> pd.DataFrame: \n",
    "    if isinstance(gt, str):\n",
    "        gt = pd.read_csv(gt)\n",
    "    if isinstance(forecasts, str):\n",
    "        forecast = pd.read_csv(forecast)\n",
    "\n",
    "    # take only the locations and dates that are forecasted\n",
    "    gt = gt[gt[\"location\"].isin(forecasts[\"location\"])]\n",
    "    gt = gt[gt[\"date\"].isin(forecasts.target_end_date)]\n",
    "\n",
    "    #first_forecast_date = datetime.datetime.strptime(forecasts[\"target_end_date\"].sort_values()[0], \"%Y-%m-%d\").date()\n",
    "    #target_dates = pd.date_range(first_forecast_date, first_forecast_date + datetime.timedelta(days=n*7), freq=\"W-SAT\").date\n",
    "\n",
    "    gt_piv = gt.pivot(index=\"date\", columns=\"location\", values=\"value\").sort_index()\n",
    "\n",
    "\n",
    "    target_dict = dict(zip(gt_piv.index, [f\"{n} wk ahead\" for n in range(1,n+1)]))\n",
    "    \n",
    "    # Alpha for WIS\n",
    "    alphas=np.array(sorted(forecasts[\"quantile\"].unique()))[:11]*2\n",
    "    \n",
    "    # gt_piv.index should be similar to target_dict.keys() apart from format\n",
    "\n",
    "    all_targets = []\n",
    "    \n",
    "    for target in target_dict.keys():\n",
    "        f = forecasts[forecasts[\"target_end_date\"] == target]\n",
    "        q_dict = {}\n",
    "        for q in f[\"quantile\"].unique():\n",
    "            q_dict[float(q)] = f[f[\"quantile\"]==q].pivot(index=[\"target_end_date\"], columns=\"location\", values=\"value\").sort_index().to_numpy().ravel()\n",
    "        wis_total, wis_sharpness, wis_calibration, underprediction, overprediction =   weighted_interval_score_fast(observations=gt_piv.loc[target].to_numpy(), \n",
    "                                                                                        alphas=alphas, \n",
    "                                                                                        q_dict=q_dict, \n",
    "                                                                                        weights=alphas/2)\n",
    "        df = pd.DataFrame([wis_total, wis_sharpness, wis_calibration, underprediction, overprediction], index = [\"wis_total\", \"wis_sharpness\", \"wis_calibration\", \"wis_underprediction\", \"wis_overprediction\"], columns=gt_piv.columns)\n",
    "        df[\"target\"] = target_dict[target]\n",
    "        df[\"target_end_date\"] = target    \n",
    "        all_targets.append(df)\n",
    "\n",
    "    \n",
    "    return pd.concat(all_targets).reset_index(names=\"wis_type\").set_index([\"target\", \"target_end_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"CADPH-FluCAT_Ensemble\",\n",
    "flusight_model_list = [ # %ls Flusight/Flusight-forecast-data/data-forecasts\n",
    " \"LUcompUncertLab-humanjudgment\",\n",
    "\"CEID-Walk\", \"LUcompUncertLab-stacked_ili\",\n",
    "\"CEPH-Rtrend_fluH\", #\"LosAlamos_NAU-CModel_Flu\",\n",
    "\"CMU-TimeSeries\", #\"METADATA.m\",\n",
    "\"CU-ensemble\", \"MIGHTE-Nsemble\",\n",
    "\"Flusight-baseline\", \"MOBS-GLEAM_FLUH\",\n",
    "\"Flusight-ensemble\", \"NIH-Flu_ARIMA\",\n",
    "\"GH-Flusight\", \"PSI-DICE\",\n",
    "\"GT-FluFNP\", #\"README.m\",\n",
    "\"IEM_Health-FluProject\", \"SGroup-RandomForest\",\n",
    "\"ISU_NiemiLab-Flu\", \"SGroup-SIkJalpha\",\n",
    "\"JHUAPL-Gecko\", #\"SigSci-CREG\",\n",
    "\"JHU_IDD-CovidSP\", #\"SigSci-TSENS\",\n",
    "\"LUcompUncertLab-HWAR2\", \"UGA_flucast-OKeeffe\",\n",
    "\"LUcompUncertLab-KalmanFilter\", \"UGuelph-FluPLUG\",\n",
    "\"LUcompUncertLab-TEVA\", \"UMass-gbq\",\n",
    "\"LUcompUncertLab-VAR2\", \"UMass-trends_ensemble\",\n",
    "\"LUcompUncertLab-VAR2K\", \"UNC_IDD-InfluPaint\",\n",
    "\"LUcompUncertLab-VAR2K_plusCOVID\", \"UT_FluCast-Voltaire\",\n",
    "\"LUcompUncertLab-VAR2_plusCOVID\", \"UVAFluX-Ensemble\",\n",
    "\"LUcompUncertLab-ensemble_rclp\", \"Umass-ARIMA\",\n",
    "#\"LUcompUncertLab-experthuman\", \"VTSanghani-ExogModel\",\n",
    "\"LUcompUncertLab-hier_mech_model\", \"VTSanghani-Transformer\"]\n",
    "\n",
    "model_list = [\"UNC_IDD-InfluPaint\"]\n",
    "model_list = flusight_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6*32/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding LUcompUncertLab-humanjudgment\n",
      ">> skipped 2022-11-14,2023-03-20,2023-04-10,2023-05-01\n",
      "Adding CEPH-Rtrend_fluH\n",
      "Adding CMU-TimeSeries\n",
      "Adding CU-ensemble\n",
      ">> skipped 2022-12-26\n",
      "Adding MIGHTE-Nsemble\n",
      "Adding Flusight-baseline\n",
      "Adding MOBS-GLEAM_FLUH\n",
      "Adding Flusight-ensemble\n",
      "Adding NIH-Flu_ARIMA\n",
      ">> skipped 2023-02-27,2023-05-01\n",
      "Adding PSI-DICE\n",
      "Adding GT-FluFNP\n",
      "Adding SGroup-RandomForest\n",
      ">> skipped 2022-12-26\n",
      "Adding ISU_NiemiLab-Flu\n",
      ">> skipped 2023-04-10,2023-05-01\n",
      "Adding JHU_IDD-CovidSP\n",
      ">> skipped 2022-12-26\n",
      "Adding UGA_flucast-OKeeffe\n",
      ">> skipped 2022-12-26\n",
      "Adding UMass-trends_ensemble\n",
      "Adding UNC_IDD-InfluPaint\n",
      "Adding UVAFluX-Ensemble\n",
      ">> skipped 2023-05-01\n"
     ]
    }
   ],
   "source": [
    "fdates = pd.date_range(\"2022-11-14\", \"2023-05-15\", freq=\"3W-MON\")\n",
    "\n",
    "gt = pd.read_csv(\"Flusight/Flusight-forecast-data/data-truth/truth-Incident Hospitalizations.csv\")\n",
    "\n",
    "\n",
    "scores = {}\n",
    "for model in model_list:\n",
    "    \n",
    "    skipped = []\n",
    "    scores[model] = {}\n",
    "    for date in fdates:\n",
    "        date = date.date()\n",
    "        try:\n",
    "            forecasts = pd.read_csv(f\"Flusight/Flusight-forecast-data/data-forecasts/{model}/{str(date)}-{model}.csv\")\n",
    "            #forecasts = pd.read_csv(f\"Flusight/Flusight-forecast-data/data-forecasts/JHU_IDD-covidSP/{str(date)}-JHU_IDD-covidSP.csv\")\n",
    "            #forecasts = pd.read_csv(f\"Flusight/Flusight-forecast-data/data-forecasts/MOBS-GLEAM_FLUH/{str(date)}-MOBS-GLEAM_FLUH.csv\")\n",
    "            forecasts = forecasts[forecasts[\"type\"]==\"quantile\"]\n",
    "            this_date=True\n",
    "        except FileNotFoundError:\n",
    "            skipped.append(date)\n",
    "            this_date=False\n",
    "        if this_date:\n",
    "            wis_all = score_Nwk_forecasts(gt, forecasts)\n",
    "            scores[model][date] = wis_all\n",
    "        \n",
    "    \n",
    "    if len(skipped) < 5:\n",
    "        print(f\"Adding {model}\")\n",
    "        if len(skipped): print(f\">> skipped {','.join([str(i) for i in skipped])}\")\n",
    "        scores[model] = pd.concat(scores[model], names=[\"forecast_date\", \"target\", \"target_end_date\"])\n",
    "    else:\n",
    "        scores.pop(model)\n",
    "        #print(f\">> Too many skipped, removing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>target</th>\n",
       "      <th>target_end_date</th>\n",
       "      <th>location</th>\n",
       "      <th>wis_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUcompUncertLab-humanjudgment</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>1 wk ahead</td>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>01</td>\n",
       "      <td>424.453978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LUcompUncertLab-humanjudgment</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>2 wk ahead</td>\n",
       "      <td>2022-12-17</td>\n",
       "      <td>01</td>\n",
       "      <td>871.445129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LUcompUncertLab-humanjudgment</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>3 wk ahead</td>\n",
       "      <td>2022-12-24</td>\n",
       "      <td>01</td>\n",
       "      <td>927.082232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LUcompUncertLab-humanjudgment</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>4 wk ahead</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>01</td>\n",
       "      <td>1069.695353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LUcompUncertLab-humanjudgment</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>1 wk ahead</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>01</td>\n",
       "      <td>673.532752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32179</th>\n",
       "      <td>UVAFluX-Ensemble</td>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>4 wk ahead</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>US</td>\n",
       "      <td>399.641256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32180</th>\n",
       "      <td>UVAFluX-Ensemble</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>1 wk ahead</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>US</td>\n",
       "      <td>410.594046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32181</th>\n",
       "      <td>UVAFluX-Ensemble</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>2 wk ahead</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>US</td>\n",
       "      <td>487.871228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32182</th>\n",
       "      <td>UVAFluX-Ensemble</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>3 wk ahead</td>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>US</td>\n",
       "      <td>609.518295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32183</th>\n",
       "      <td>UVAFluX-Ensemble</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>4 wk ahead</td>\n",
       "      <td>2023-05-06</td>\n",
       "      <td>US</td>\n",
       "      <td>384.819223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32184 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model forecast_date      target  \\\n",
       "0      LUcompUncertLab-humanjudgment    2022-12-05  1 wk ahead   \n",
       "1      LUcompUncertLab-humanjudgment    2022-12-05  2 wk ahead   \n",
       "2      LUcompUncertLab-humanjudgment    2022-12-05  3 wk ahead   \n",
       "3      LUcompUncertLab-humanjudgment    2022-12-05  4 wk ahead   \n",
       "4      LUcompUncertLab-humanjudgment    2022-12-26  1 wk ahead   \n",
       "...                              ...           ...         ...   \n",
       "32179               UVAFluX-Ensemble    2023-03-20  4 wk ahead   \n",
       "32180               UVAFluX-Ensemble    2023-04-10  1 wk ahead   \n",
       "32181               UVAFluX-Ensemble    2023-04-10  2 wk ahead   \n",
       "32182               UVAFluX-Ensemble    2023-04-10  3 wk ahead   \n",
       "32183               UVAFluX-Ensemble    2023-04-10  4 wk ahead   \n",
       "\n",
       "      target_end_date location    wis_total  \n",
       "0          2022-12-10       01   424.453978  \n",
       "1          2022-12-17       01   871.445129  \n",
       "2          2022-12-24       01   927.082232  \n",
       "3          2022-12-31       01  1069.695353  \n",
       "4          2022-12-31       01   673.532752  \n",
       "...               ...      ...          ...  \n",
       "32179      2023-04-15       US   399.641256  \n",
       "32180      2023-04-15       US   410.594046  \n",
       "32181      2023-04-22       US   487.871228  \n",
       "32182      2023-04-29       US   609.518295  \n",
       "32183      2023-05-06       US   384.819223  \n",
       "\n",
       "[32184 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores = pd.concat(scores, names=[\"model\", \"forecast_date\", \"target\", \"target_end_date\"])\n",
    "wis_total = all_scores[all_scores[\"wis_type\"] == \"wis_total\"].drop(\"wis_type\", axis=1)\n",
    "wis_total  = pd.melt(wis_total , var_name=\"location\", value_name=\"wis_total\",ignore_index=False).reset_index()\n",
    "\n",
    "wis_underprediction = all_scores[all_scores[\"wis_type\"] == \"wis_underprediction\"].drop(\"wis_type\", axis=1)\n",
    "wis_underprediction = pd.melt(wis_underprediction , var_name=\"location\", value_name=\"wis_underprediction\",ignore_index=False).reset_index()\n",
    "\n",
    "wis_overprediction = all_scores[all_scores[\"wis_type\"] == \"wis_overprediction\"].drop(\"wis_type\", axis=1)\n",
    "wis_overprediction = pd.melt(wis_overprediction , var_name=\"location\", value_name=\"wis_overprediction\",ignore_index=False).reset_index()\n",
    "\n",
    "wis_sharpness = all_scores[all_scores[\"wis_type\"] == \"wis_sharpness\"].drop(\"wis_type\", axis=1)\n",
    "wis_sharpness = pd.melt(wis_sharpness , var_name=\"location\", value_name=\"wis_sharpness\",ignore_index=False).reset_index()\n",
    "\n",
    "wis_total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wis_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MOBS-GLEAM_FLUH</th>\n",
       "      <td>1.541851e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMU-TimeSeries</th>\n",
       "      <td>1.802241e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSI-DICE</th>\n",
       "      <td>1.967445e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIH-Flu_ARIMA</th>\n",
       "      <td>1.994083e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flusight-ensemble</th>\n",
       "      <td>2.083896e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIGHTE-Nsemble</th>\n",
       "      <td>2.150634e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGroup-RandomForest</th>\n",
       "      <td>2.158199e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GT-FluFNP</th>\n",
       "      <td>2.273337e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMass-trends_ensemble</th>\n",
       "      <td>2.352290e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEPH-Rtrend_fluH</th>\n",
       "      <td>2.464946e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UGA_flucast-OKeeffe</th>\n",
       "      <td>2.714379e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNC_IDD-InfluPaint</th>\n",
       "      <td>2.718236e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVAFluX-Ensemble</th>\n",
       "      <td>2.997418e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flusight-baseline</th>\n",
       "      <td>3.023941e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JHU_IDD-CovidSP</th>\n",
       "      <td>6.302899e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          wis_total\n",
       "model                              \n",
       "MOBS-GLEAM_FLUH        1.541851e+06\n",
       "CMU-TimeSeries         1.802241e+06\n",
       "PSI-DICE               1.967445e+06\n",
       "NIH-Flu_ARIMA          1.994083e+06\n",
       "Flusight-ensemble      2.083896e+06\n",
       "MIGHTE-Nsemble         2.150634e+06\n",
       "SGroup-RandomForest    2.158199e+06\n",
       "GT-FluFNP              2.273337e+06\n",
       "UMass-trends_ensemble  2.352290e+06\n",
       "CEPH-Rtrend_fluH       2.464946e+06\n",
       "UGA_flucast-OKeeffe    2.714379e+06\n",
       "UNC_IDD-InfluPaint     2.718236e+06\n",
       "UVAFluX-Ensemble       2.997418e+06\n",
       "Flusight-baseline      3.023941e+06\n",
       "JHU_IDD-CovidSP        6.302899e+06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = wis_total[[\"wis_total\",\"model\"]].groupby(\"model\").sum().sort_values(by=\"wis_total\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wis_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NIH-Flu_ARIMA</th>\n",
       "      <td>5.347349e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU-ensemble</th>\n",
       "      <td>5.854500e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOBS-GLEAM_FLUH</th>\n",
       "      <td>6.573592e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMU-TimeSeries</th>\n",
       "      <td>6.624845e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGroup-RandomForest</th>\n",
       "      <td>6.850440e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GT-FluFNP</th>\n",
       "      <td>7.831573e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSI-DICE</th>\n",
       "      <td>7.847929e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UGA_flucast-OKeeffe</th>\n",
       "      <td>7.948820e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUcompUncertLab-humanjudgment</th>\n",
       "      <td>8.451724e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flusight-ensemble</th>\n",
       "      <td>8.552829e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMass-trends_ensemble</th>\n",
       "      <td>9.360156e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIGHTE-Nsemble</th>\n",
       "      <td>9.485289e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEPH-Rtrend_fluH</th>\n",
       "      <td>1.069242e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flusight-baseline</th>\n",
       "      <td>1.088930e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UVAFluX-Ensemble</th>\n",
       "      <td>1.220717e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNC_IDD-InfluPaint</th>\n",
       "      <td>1.523183e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISU_NiemiLab-Flu</th>\n",
       "      <td>1.713489e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JHU_IDD-CovidSP</th>\n",
       "      <td>3.125552e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  wis_total\n",
       "model                                      \n",
       "NIH-Flu_ARIMA                  5.347349e+05\n",
       "CU-ensemble                    5.854500e+05\n",
       "MOBS-GLEAM_FLUH                6.573592e+05\n",
       "CMU-TimeSeries                 6.624845e+05\n",
       "SGroup-RandomForest            6.850440e+05\n",
       "GT-FluFNP                      7.831573e+05\n",
       "PSI-DICE                       7.847929e+05\n",
       "UGA_flucast-OKeeffe            7.948820e+05\n",
       "LUcompUncertLab-humanjudgment  8.451724e+05\n",
       "Flusight-ensemble              8.552829e+05\n",
       "UMass-trends_ensemble          9.360156e+05\n",
       "MIGHTE-Nsemble                 9.485289e+05\n",
       "CEPH-Rtrend_fluH               1.069242e+06\n",
       "Flusight-baseline              1.088930e+06\n",
       "UVAFluX-Ensemble               1.220717e+06\n",
       "UNC_IDD-InfluPaint             1.523183e+06\n",
       "ISU_NiemiLab-Flu               1.713489e+06\n",
       "JHU_IDD-CovidSP                3.125552e+06"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = wis_total[[\"wis_total\",\"model\"]].groupby(\"model\").sum().sort_values(by=\"wis_total\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = wis_total[wis_total[\"location\"]==\"US\"].pivot(values=\"wis_total\", index=\"target\", columns=\"forecast_date\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(np.log(tp), annot=False, fmt=\"\", linewidths=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = wis_total[wis_total[\"target\"]==\"1 wk ahead\"].pivot(values=\"wis_total\", index=\"location\", columns=\"forecast_date\")\n",
    "tp = np.log(tp)\n",
    "f, ax = plt.subplots(figsize=(9, 12))\n",
    "sns.heatmap(np.log(tp), annot=False, fmt=\"\", linewidths=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = wis_total.pivot(values=\"wis_total\", index=\"location\", columns=[\"forecast_date\",\"target\"])\n",
    "# tp = np.log(tp)\n",
    "# f, ax = plt.subplots(figsize=(12, 12), dpi=300)\n",
    "# sns.heatmap(np.log(tp), annot=False, fmt=\"\", linewidths=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = wis_underprediction[wis_underprediction[\"location\"]==\"US\"].pivot(values=\"wis_underprediction\", index=\"target\", columns=\"forecast_date\")\n",
    "tp2 = wis_overprediction[wis_overprediction[\"location\"]==\"US\"].pivot(values=\"wis_overprediction\", index=\"target\", columns=\"forecast_date\")\n",
    "\n",
    "tp1 = wis_sharpness[wis_sharpness[\"location\"]==\"US\"].pivot(values=\"wis_sharpness\", index=\"target\", columns=\"forecast_date\")\n",
    "tp2 = wis_total[wis_total[\"location\"]==\"US\"].pivot(values=\"wis_total\", index=\"target\", columns=\"forecast_date\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(tp1/tp2, annot=False, fmt=\"\", linewidths=1, ax=ax)\n",
    "print((tp1/tp2).mean().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = wis_underprediction[wis_underprediction[\"location\"]==\"US\"].pivot(values=\"wis_underprediction\", index=\"target\", columns=\"forecast_date\")\n",
    "#tp2 = wis_overprediction[wis_overprediction[\"location\"]==\"US\"].pivot(values=\"wis_overprediction\", index=\"target\", columns=\"forecast_date\")\n",
    "\n",
    "tp2 = wis_total[wis_total[\"location\"]==\"US\"].pivot(values=\"wis_total\", index=\"target\", columns=\"forecast_date\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(tp1/tp2, annot=False, fmt=\"\", linewidths=1, ax=ax)\n",
    "print((tp1/tp2).mean().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = wis_overprediction[wis_overprediction[\"location\"]==\"US\"].pivot(values=\"wis_overprediction\", index=\"target\", columns=\"forecast_date\")\n",
    "\n",
    "tp2 = wis_total[wis_total[\"location\"]==\"US\"].pivot(values=\"wis_total\", index=\"target\", columns=\"forecast_date\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(tp1/tp2, annot=False, fmt=\"\", linewidths=1, ax=ax)\n",
    "print((tp1/tp2).mean().mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion_torch65)",
   "language": "python",
   "name": "diffusion_torch6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
